背景
风控二分类


数据特点


主要想法：
使用xgboost

使用的套路：
缺失值怎样填补？
缺失值变量如果太多，可以将其剔除。
类别变量：  1）采用众数将其填充
连续型数值特征  1）采用平均值或者中位数将其填充
另外一种填充方法：将其当成某一类值进行填充
当然在真实业务中，还有根据该变量的特点进行填充。

数据的填充往往会引入更多的噪声。
可以将有其特征和没有其特征代入模型中看验证集和测试集的准确率

特征分布情况：
连续型变量：将数据均等分，然后观察其分布。
离散型变量：每个类别进行等分，然后观察其分布。
数据的特点是：标注数据30万，未标注数据70万，预测数据集2万。
如何利用这70万的数据集是一个大的问题。
将同一变量训练集和测试集的分布之间有明显差异的将其剔除。因为分布不稳定，可能会是噪声。

变量构造：
针对连续型变量，多个变量之间做乘法，做加法。然后进行特征选择。
针对金融类数据，将各种金融指数加进去。

xgboost做特征选择的原理：
每个特征在多棵树中可能会存在多次调用。将该特征在整个森林中使用到的次数进行加和记为该特征的重要度。

gbdt做特征选择的原理：
每做一次特征选择，损失函数会减少，将每棵树中使用该特征进行分裂时减少的量，进行加和，除以树的总数，就是该变量的特征重要性。

xgboost调参数经验：
0. 先固定学习率。通常在0.05到0.2之间。一般设置为0.1。等到其他参数都确定下来后，再降低学习率
1. 一般先调整树的个数，一般树的个数设置为100以内。可以在10-100内进行搜索。
   调参数的过程中，需要设置其他的一些树的参数。
   min_samples_split=500，这个是指当某一节点只有500个样本的时候还要不要继续分裂。这个值应该在总样本数的0.5%-1%之间。
   min_sample_leaf这个是每个叶子节点的最小样本数。为了防止过拟合，一般不要设置过少。
   max_depth，树的最大深度。 一般根据自变量个数进行设置；
   subsample一般都用0.8
2. 依次调节  min_samples_split: 1200
            min_samples_leaf: 60
            max_depth: 9
            max_features: 7

最后调整learning rate





 













1. 突发事件如何检测？（目前没有办法做）
1）个人行为异常。正常的定义
2）借助图像、语音等手段
3）

2. 通用模型怎么训练？
1）多任务学习
多任务学习(Multi-task learning)是迁移学习（Transfer Learning）的一种，而迁移学习指的是将从源领域的知识（source domin）学到的知识用于目标领域(target domin)，提升目标领域的学习效果。 而多任务学习也是希望模型同时做多个任务时，能将其他任务学到的知识，用于目标任务中，从而提升目标任务效果。

如果我们换个角度理解，其实多任务学习，其实是对目标任务做了一定的约束，或者叫做regularization。我们不希望模型只局限于目标任务的学习，而是能够适应多个任务场景，这样可以大大的增加模型的泛函能力(generalization)。

举个形象的例子，单人多任务学习模型就像一个一门心思只做一样事情的匠人，在他自己的领域，他可能可以做一百分，如果换个任务也许他就会做的不是特别好，而多任务学习模型就像一个什么任务都做得还算优秀但是不完美的人。可是在实际深度学习任务中，测试集和训练集的分布还是会有一定的偏差，那测试集可能就意味给让模型做一个目标微调后任务。所以在测试集上，多任务模型大概率是表现优异那一个。

这里需要强调一点，这里的多任务的各个任务之间一定要有强相关性，如果任务之间本身的关联性就不大，多任务学习并不会对模型的提升并不一定会有用。

多任务学习(Multi-task learning)的两种模式
深度学习中两种多任务学习模式：隐层参数的硬共享与软共享。 + 隐层参数硬共享，指的是多个任务之间共享网络的同几层隐藏层，只不过在网络的靠近输出部分开始分叉去做不同的任务。 + 隐层参数软共享，不同的任务使用不同的网络，但是不同任务的网络参数，采用距离(L1,L2)等作为约束，鼓励参数相似化。


3. 如何做异常检测或者聚类？
1）
2）
3）


4. 样本生成怎么做？
1）对抗学习。 在图像中应用比较广泛。在风控中效果可能不好，因为变量分布不平滑

2）smote
   思想：类别多的和类别少的，对类别少的进行样本生成，两者尽量1:1.
        伪代码：
        1）根据样本比例情况，设置一个样本生成多少个样本
        2）取样本量少对样本，找到这个样本距离最近的（连续型变量和离散变量，取欧式距离，针对离散变量可以根据对业务对理解设置权重）样本，然后在两个样本对连线上做random取值
        3）重复2）直到结束
5. 怎么利用目前积累的样本？
1）可以利用已有样本进行active learning。
   伪代码：
   （1）标注一小批数据
   （2）训练一个分类器
   （3）将未标注数据使用分类器进行预测，将信息量比较大的样本进行标注
   （4）重新训练分类器
   （5）重复（3）（4）

2）多任务学习


3）迁移学习
